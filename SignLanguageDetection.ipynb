{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkGe0p-T1PLM"
   },
   "source": [
    "**Actions We Want To Detect**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VjKfqq911vve"
   },
   "outputs": [],
   "source": [
    "actions = ['book', 'drink', 'hello', 'idea']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVtQp6e81wjt"
   },
   "source": [
    "Import Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7JU7q57ium3a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fE7lPnr-rrDn"
   },
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEFie6hvtv5O"
   },
   "source": [
    "**WLASL (World Level American Sign Language) Video**\n",
    "\n",
    "WLASL is the largest video dataset for Word-Level ASL recognition, which features 2,000 common different words in ASL.\n",
    "\n",
    "Options:\n",
    "\n",
    "1. Get From Kaggle\n",
    "\n",
    "2. Download From URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORAVO1wQx8uz"
   },
   "outputs": [],
   "source": [
    "option = 1  # or 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UTbY2Z6uFaq"
   },
   "source": [
    "**Option 1: Get From Kaggle**\n",
    "\n",
    "Gets all data (about 5GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuDuSPYfuEyB"
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"risangbaskoro/wlasl-processed\")\n",
    "\n",
    "!cp -r {path} /content/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wo8Q-dpSuJW1"
   },
   "source": [
    "**Option 2: Download From URLs**\n",
    "\n",
    "Customizable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3NVw2qxTruXe",
    "outputId": "ef0def77-73f3-40e7-d0c4-06f73485cade"
   },
   "outputs": [],
   "source": [
    "!pip install yt-dlp\n",
    "!apt update && apt install -y ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kOGJbficuj8a"
   },
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wcY4N4SyIbm"
   },
   "source": [
    "Video **Download**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkktdLldIF8C"
   },
   "outputs": [],
   "source": [
    "!rm -rf videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ejg9CHixrNV"
   },
   "outputs": [],
   "source": [
    "def download_video(url, save_dir='downloads'):\n",
    "    Path(save_dir).mkdir(exist_ok=True)\n",
    "\n",
    "    parsed_url = urlparse(url)\n",
    "    ext = os.path.splitext(parsed_url.path)[-1]\n",
    "    filename = parsed_url.path.split(\"/\")[-1]\n",
    "\n",
    "    if not filename or not ext:\n",
    "        print(f\"Skipping unknown format: {url}\")\n",
    "        return None\n",
    "\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "\n",
    "    # Skip existing files\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"Already exists: {save_path}\")\n",
    "        return save_path\n",
    "\n",
    "    try:\n",
    "        if \"youtube.com\" in url or \"youtu.be\" in url:\n",
    "            import yt_dlp\n",
    "            ydl_opts = {\n",
    "                'outtmpl': os.path.join(save_dir, '%(id)s.%(ext)s'),\n",
    "                'quiet': True,\n",
    "                'format': 'bestvideo+bestaudio/best',\n",
    "                'merge_output_format': 'mp4',\n",
    "            }\n",
    "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "                ydl.download([url])\n",
    "            print(f\"YouTube downloaded: {url}\")\n",
    "            return save_dir  # may return folder if unknown file\n",
    "        elif ext in ['.mp4', '.mov']:\n",
    "            r = requests.get(url, stream=True, timeout=10)\n",
    "            if r.status_code == 200:\n",
    "                with open(save_path, 'wb') as f:\n",
    "                    for chunk in r.iter_content(1024 * 1024):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "                print(f\"Downloaded: {save_path}\")\n",
    "                return save_path\n",
    "            else:\n",
    "                print(f\"HTTP {r.status_code}: {url}\")\n",
    "                return None\n",
    "        elif ext == '.swf':\n",
    "            print(f\"Skipping unsupported .swf: {url}\")\n",
    "            return None\n",
    "        else:\n",
    "            print(f\"Unknown or unsupported format: {url}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Failed: {url} | Error: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRyCfrdWLPLX"
   },
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pMIudoDiIUNJ",
    "outputId": "b4ae9515-7080-4cf8-bf2b-e2e82e667d88"
   },
   "outputs": [],
   "source": [
    "video_urls = [\n",
    "    # Idea\n",
    "    \"https://elementalaslconcepts.weebly.com/uploads/2/4/4/5/24454483/idea.mov\",\n",
    "    \"https://media.spreadthesign.com/video/mp4/13/244655.mp4\",\n",
    "    \"https://signstock.blob.core.windows.net/signschool/videos/db_uploads/SignSchool%20Idea%2C%20Imagine-3YjmVax6CBc.mp4\",\n",
    "    \"https://signstock.blob.core.windows.net/signschool/videos/db_uploads/SignSchool%20Idea-HR8afgGna7A.mp4\",\n",
    "    \"https://media.asldeafined.com/vocabulary/1468665115.4947.mp4\",\n",
    "\n",
    "    # Hello\n",
    "    \"https://signstock.blob.core.windows.net/signschool/videos/db_uploads/SignSchool%20Hello-6kvCOzxP9_A.mp4\",\n",
    "    \"https://media.asldeafined.com/vocabulary/1468580623.2588.mp4\",\n",
    "    \"https://www.handspeak.com/word/h/hello.mp4\",\n",
    "    \"https://www.signingsavvy.com/signs/mp4/6/6353.mp4\",\n",
    "]\n",
    "\n",
    "for url in video_urls:\n",
    "    download_video(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_0BfLxkqQAl"
   },
   "source": [
    "**Get keypoints with Mediapipe**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXxuzw6jz9yg"
   },
   "source": [
    "**MediaPipe Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "C-dZ4mX0uVtZ",
    "outputId": "f05f67a6-c38b-45a8-d706-770c304bf552"
   },
   "outputs": [],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gj0YxcILub6r"
   },
   "outputs": [],
   "source": [
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bostib3gqYf6"
   },
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "holistic = mp_holistic.Holistic(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x8j7ak6SzrhT"
   },
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]) if results.pose_landmarks else np.zeros((33, 4))\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]) if results.face_landmarks else np.zeros((468, 3))\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]) if results.left_hand_landmarks else np.zeros((21, 3))\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]) if results.right_hand_landmarks else np.zeros((21, 3))\n",
    "    return np.concatenate([pose.flatten(), face.flatten(), lh.flatten(), rh.flatten()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2995DP-z6I4"
   },
   "source": [
    "**Process and Save Keypoints**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loZ3BZxuz4AB"
   },
   "outputs": [],
   "source": [
    "def process_video(video_path, start_frame=1, end_frame=None, bbox=None, fps=25):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Cannot open video: {video_path}\")\n",
    "        return []\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    end_frame = end_frame if end_frame and end_frame > 0 else total_frames\n",
    "\n",
    "    keypoints = []\n",
    "\n",
    "    for frame_num in range(start_frame, end_frame):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Apply bounding box crop if provided\n",
    "        if bbox:\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            frame = frame[y1:y2, x1:x2]\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(frame_rgb)\n",
    "        keypoints.append(extract_keypoints(results))\n",
    "\n",
    "    cap.release()\n",
    "    return np.array(keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIMaAyfL0C_I"
   },
   "source": [
    "**Main Loop: Load JSON & Save Keypoints**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624,
     "referenced_widgets": [
      "407c82f17dcd46eaa40df32daf88d020",
      "ac44dd40dbab4c768936b4df14226cc5",
      "1683b83fabf54bdd9fe5c23a851a6d9e",
      "7affab0cf7d744fa8a9c703e6d37131d",
      "1bb9cff4e84c40649e3e977dab5d5143",
      "cfd85b799d214a1da4b14e0e76986fec",
      "44b63093302a432bad35908c1402369c",
      "6cdc2636081e43c98b05c2258de702c5",
      "fc74befca249410abaad0ce059baa3ae",
      "87932ae01b3c46aaa814d941fd985b07",
      "b2bdb6b68d4e4e70a687fcb909cb4455"
     ]
    },
    "id": "ghYQ8gQC0ETY",
    "outputId": "c23fbd9f-37d4-4ece-b715-74bbd29c5880"
   },
   "outputs": [],
   "source": [
    "with open(\"5/WLASL_Sample.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for gloss_entry in tqdm(data):\n",
    "    gloss = gloss_entry[\"gloss\"]\n",
    "\n",
    "    # Skip glosses not in the action list\n",
    "    if gloss not in actions:\n",
    "        continue\n",
    "\n",
    "    print(gloss)\n",
    "    for inst in gloss_entry[\"instances\"]:\n",
    "        url = inst[\"url\"]\n",
    "        bbox = inst.get(\"bbox\", None)\n",
    "        start = inst.get(\"frame_start\", 1)\n",
    "        end = inst.get(\"frame_end\", -1)\n",
    "        fps = inst.get(\"fps\", 25)\n",
    "        video_id = inst[\"video_id\"]\n",
    "\n",
    "        if option == 1:\n",
    "            path = '5/videos'\n",
    "            video_path = os.path.join(path, f'{video_id}.mp4')\n",
    "        elif option == 2:\n",
    "            video_path = download_video(url)\n",
    "            if video_path is None:\n",
    "                continue\n",
    "\n",
    "        keypoints = process_video(video_path, start_frame=start, end_frame=end, bbox=bbox, fps=fps)\n",
    "        if len(keypoints) == 0:\n",
    "            continue\n",
    "\n",
    "        save_dir = f\"keypoints/{gloss}\"\n",
    "        Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "        np.save(f\"{save_dir}/{video_id}.npy\", keypoints)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uck2JsGCLGjc"
   },
   "source": [
    "Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jxl9iG4dKGqI",
    "outputId": "98be0b42-343a-4ffe-b117-5a38739e264b"
   },
   "outputs": [],
   "source": [
    "np.load('keypoints/drink/17720.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3-nFz68PNJL"
   },
   "source": [
    "Download&Upload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7MMd2N3gMhXD",
    "outputId": "61171fc6-99f7-484e-beda-459ee3371ecd"
   },
   "outputs": [],
   "source": [
    "!zip -r /content/file.zip /content/keypoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8oSLp47PTPS",
    "outputId": "c7c9614d-4163-409f-fe4e-0b038625908a"
   },
   "outputs": [],
   "source": [
    "!unzip /content/file.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifdu-0BZLHps"
   },
   "source": [
    "# Preprocess Data and Create Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NbgDBS-oLIxC"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VdUTU_EfRxQF"
   },
   "outputs": [],
   "source": [
    "# Set desired number of frames (sequence length)\n",
    "MAX_FRAMES = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g6pfWTlPLnti",
    "outputId": "958562e9-e4a6-48d8-f430-e24dc1e03396"
   },
   "outputs": [],
   "source": [
    "data_dir = 'keypoints'\n",
    "X = []  # features\n",
    "y = []  # labels\n",
    "label_map = {}  # class name -> index\n",
    "\n",
    "for i, label in enumerate(os.listdir(data_dir)):\n",
    "    label_path = os.path.join(data_dir, label)\n",
    "    if not os.path.isdir(label_path):\n",
    "        continue\n",
    "    label_map[label] = i  # \"book\" -> 0, \"drink\" -> 1, etc.\n",
    "\n",
    "    for file in os.listdir(label_path):\n",
    "        if file.endswith('.npy'):\n",
    "            keypoints = np.load(os.path.join(label_path, file))\n",
    "            if len(keypoints.shape) != 2:  # (frames, features)\n",
    "                continue  # skip corrupted or empty files\n",
    "            X.append(keypoints)\n",
    "            y.append(i)\n",
    "\n",
    "\n",
    "# Pad all sequences to shape (MAX_FRAMES, num_features)\n",
    "X = pad_sequences(X, maxlen=MAX_FRAMES, dtype='float32', padding='post', truncating='post')\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"X shape:\", X.shape)  # should be (num_samples, MAX_FRAMES, features)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s4vZDqH7SWpg",
    "outputId": "9f9d8902-23cb-4e0d-9923-520d64b6bc60"
   },
   "outputs": [],
   "source": [
    "# Split train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# ensure they're NumPy arrays (if still in list form)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xtmw4i2ITF4M",
    "outputId": "fb9ff592-a111-4ca4-fcdd-ed304eeee1cc"
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9IJKGc0TaC-"
   },
   "source": [
    "# Build Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YI1Ts7_FTe-D"
   },
   "source": [
    "LSTM Neural Network"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
